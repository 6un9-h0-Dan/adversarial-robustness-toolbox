{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steal Now and Attack Later\n",
    "\n",
    "This notebook provides a demonstration showing how to use ART to launch the SNAL attack [1].\n",
    "\n",
    "The core concept of this attack is to first collect objects from any model and then in a second step append valid patches to the target image and weaken the impact of unimportant pixels.\n",
    "\n",
    "\n",
    "[1] Steal Now and Attack Later: Evaluating Robustness of Object Detection against Black-box Adversarial Attacks (https://arxiv.org/abs/2404.15881)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Any\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(level=logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Download the target image from MS COCO dataset\n",
    "from io import BytesIO\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "def load_image(img_path, img_size=(640, 640), unsqueeze=True):\n",
    "\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img = img.resize((img_size[1], img_size[0]))\n",
    "\n",
    "    # convert to pytorch tensor\n",
    "    img = np.array(img).transpose((2, 0, 1))\n",
    "    img = np.ascontiguousarray(img)\n",
    "    img_tensor = torch.from_numpy(img).to(torch.float32) / 255.0\n",
    "\n",
    "    # adjust dims accordingly\n",
    "    if unsqueeze:\n",
    "        img_tensor = torch.unsqueeze(img_tensor, 0)\n",
    "\n",
    "    return img_tensor\n",
    "\n",
    "def save_img(img_tensor, file_name):\n",
    "\n",
    "    if len(img_tensor.shape) == 4:\n",
    "        raise NotImplementedError(\"img_tensor.shape should be 3\")\n",
    "\n",
    "    img = torchvision.transforms.ToPILImage()(img_tensor)\n",
    "    img.save(file_name)\n",
    "\n",
    "TARGET = 'https://farm2.staticflickr.com/1065/705706084_39a7f28fc9_z.jpg' # val2017/000000552842.jpg\n",
    "response = requests.get(TARGET)\n",
    "img = np.asarray(Image.open(BytesIO(response.content)).resize((640, 640)))\n",
    "img = np.array(img).transpose((2, 0, 1))\n",
    "img = np.ascontiguousarray(img)\n",
    "img_pt = torch.from_numpy(img).to(torch.float32) / 255.0\n",
    "save_img(img_pt, 'target.png')\n",
    "x_pt = load_image('target.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Download YOLO model\n",
    "# If ultralytics is not found, please run the command: `pip install ultralytics`\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class TYOLOv8():\n",
    "    def __init__(self, \n",
    "                 model_name: str,\n",
    "                 output_folder: str,\n",
    "                 img_dim: int) -> None:\n",
    "\n",
    "        self.bcount = 0\n",
    "        self.img_dim = img_dim\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.amp = False\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.set_model(model_name)\n",
    "        self.create_folder()\n",
    "\n",
    "    def set_model(self, model_name) -> None:\n",
    "        self.model = YOLO(model_name)\n",
    "\n",
    "    def print(self):\n",
    "        logger.info(f\"model name: {self.model_name}\")\n",
    "        logger.info(f\"total query: {self.bcount}\")\n",
    "\n",
    "    def count_reset(self) -> None:\n",
    "        self.bcount = 0\n",
    "\n",
    "    def count(self, x : torch.tensor) -> None:\n",
    "        self.bcount = self.bcount + x.shape[0]\n",
    "\n",
    "    def create_folder(self) -> None:\n",
    "        dummy_img = torch.zeros([1, 3, self.img_dim, self.img_dim], device=self.device)\n",
    "        self.model(dummy_img, save=True)\n",
    "        self.output_folder = self.model.predictor.save_dir\n",
    "\n",
    "    def transform(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x\n",
    "\n",
    "    def inference(self, x : torch.tensor) -> list:\n",
    "        pred = self.forwad(x)\n",
    "        out = []\n",
    "        for obj in pred:\n",
    "            out.append(obj.boxes.xyxy)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def forwad(self, x: torch.Tensor) -> Any:\n",
    "        self.count(x)\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast(self.amp):\n",
    "            output = self.model(self.transform(x))\n",
    "        return output\n",
    "\n",
    "    def eval_img(self, f_name):\n",
    "        self.bcount = self.bcount + 1\n",
    "        results = self.model(f_name, save=True)\n",
    "        num_boxes = results[0].boxes.xyxy.shape[0]\n",
    "        logger.info(f'*** total boxes in the eval_img: {num_boxes} ***')\n",
    "        return num_boxes\n",
    "\n",
    "model = TYOLOv8('yolov8m', './', 640)\n",
    "model.eval_img('target.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Collect patches from a set of images\n",
    "\n",
    "import glob\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "\n",
    "from art.attacks.evasion import collect_patches_from_images\n",
    "class CustomDatasetFolder(VisionDataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        super(CustomDatasetFolder, self).__init__(root)\n",
    "        self.transform = transform\n",
    "        samples = glob.glob(f\"{root}/*.jpg\")\n",
    "\n",
    "        self.samples = samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self._loader(self.samples[index])\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def _loader(self, path):\n",
    "        return Image.open(path).convert(\"RGB\")\n",
    "\n",
    "ROOT_MSCOCO = '/dataset/val2017/'\n",
    "img_dataset = CustomDatasetFolder(\n",
    "            ROOT_MSCOCO,\n",
    "            transforms.Compose([\n",
    "            transforms.RandomResizedCrop((640,640)),\n",
    "            transforms.AutoAugment(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "        ]))\n",
    "img_loader = torch.utils.data.DataLoader(img_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "candidates_list = []\n",
    "TILE_SIZE = 64\n",
    "MAX_IMGS = 1000\n",
    "img_count = 0\n",
    "for x in iter(img_loader):\n",
    "    img_count = img_count + 1\n",
    "    if img_count == MAX_IMGS:\n",
    "        break\n",
    "\n",
    "    candidates, _ = collect_patches_from_images(model, x)\n",
    "    print(f'Number of objects are detected: {len(candidates[0])}')\n",
    "    candidates_list = candidates_list + candidates[0]\n",
    "\n",
    "print(len(candidates_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import SNAL\n",
    "attack = SNAL(model,\n",
    "              eps = 16.0 /255.0,\n",
    "              max_iter = 400,\n",
    "              num_grid = 10)\n",
    "attack.set_candidates(candidates_list)\n",
    "x_adv = attack.generate(img_pt[None, :].numpy())\n",
    "adv_np = np.transpose(x_adv[0, :] * 255.0, (1, 2, 0)).astype(np.uint8)\n",
    "Image.fromarray(adv_np).save(f'{model.output_folder}/output.png')\n",
    "model.eval_img(f'{model.output_folder}/output.png')\n",
    "model.print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
